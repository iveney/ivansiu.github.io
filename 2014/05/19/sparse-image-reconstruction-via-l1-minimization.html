<!DOCTYPE html>
<!--
    So Simple Jekyll Theme 3.2.0
    Copyright 2013-2019 Michael Rose - mademistakes.com | @mmistakes
    Free for personal and commercial use under the MIT license
    https://github.com/mmistakes/so-simple-theme/blob/master/LICENSE
-->
<html lang="en-US" class="no-js">
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  

  
    
    <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Sparse Image Reconstruction via L1-minimization | Ivan Xiao</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Sparse Image Reconstruction via L1-minimization" />
<meta name="author" content="Ivan Xiao" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="nocite: ‘@candes2005l1, @hesthavensparse, @pant2013new, @candes2006robust’ —" />
<meta property="og:description" content="nocite: ‘@candes2005l1, @hesthavensparse, @pant2013new, @candes2006robust’ —" />
<link rel="canonical" href="https://www.ivansiu.com/2014/05/19/sparse-image-reconstruction-via-l1-minimization" />
<meta property="og:url" content="https://www.ivansiu.com/2014/05/19/sparse-image-reconstruction-via-l1-minimization" />
<meta property="og:site_name" content="Ivan Xiao" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2014-05-19T20:12:36+00:00" />
<script type="application/ld+json">
{"url":"https://www.ivansiu.com/2014/05/19/sparse-image-reconstruction-via-l1-minimization","headline":"Sparse Image Reconstruction via L1-minimization","dateModified":"2014-05-19T20:12:36+00:00","datePublished":"2014-05-19T20:12:36+00:00","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://www.ivansiu.com/2014/05/19/sparse-image-reconstruction-via-l1-minimization"},"author":{"@type":"Person","name":"Ivan Xiao"},"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"https://www.ivansiu.com/images/xiao.png"},"name":"Ivan Xiao"},"description":"nocite: ‘@candes2005l1, @hesthavensparse, @pant2013new, @candes2006robust’ —","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


  

  <script>
    /* Cut the mustard */
    if ( 'querySelector' in document && 'addEventListener' in window ) {
      document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + 'js';
    }
  </script>

  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="stylesheet" href="/assets/css/skins/dark.css">
  <link rel="alternate" type="application/atom+xml" title="Ivan Xiao" href="/feed.xml">
<!-- start custom head snippets -->

<!-- insert favicons. use http://realfavicongenerator.net/ -->
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/site.webmanifest">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff">

<!-- end custom head snippets -->

</head>


  <body class="layout--post  sparse-image-reconstruction-via-l1-minimization">
    <nav class="skip-links">
  <h2 class="screen-reader-text">Skip links</h2>
  <ul>
    <li><a href="#primary-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    
  <div class="navigation-wrapper">
    <a href="#menu-toggle" id="menu-toggle">Menu</a>
    <nav id="primary-nav" class="site-nav animated drop">
      <ul><li><a href="/">Home</a></li><li><a href="/categories/">Categories</a></li><li><a href="/tags/">Tags</a></li><li><a href="/search/">Search</a></li></ul>
    </nav>
  </div><!-- /.navigation-wrapper -->


    <header class="masthead">
  <div class="wrap">
    
      <a href="/" class="site-logo" rel="home" title="Ivan Xiao">
        <img src="/images/xiao.png" class="site-logo-img animated fadeInDown" alt="Ivan Xiao">
      </a>
    
    
    
      
        <div class="site-title animated fadeIn"><a href="/">Ivan Xiao</a></div>
      
      <p class="site-description animated fadeIn" itemprop="description">Engineer. Father. Cat Lover. Guitarist. Ballroom Dancer. Woodworker.</p>
    
  </div>
</header><!-- /.masthead -->


    <main id="main" class="main-content" aria-label="Content">
  <article class="h-entry">
    

    <div class="page-wrapper">
      <header class="page-header">
        
        
          <h1 id="page-title" class="page-title p-name">Sparse Image Reconstruction via L1-minimization
</h1>
        
      </header>

      <div class="page-sidebar">
        <div class="page-author h-card p-author"><img src="/images/ivan-memoji.jpg" class="author-avatar u-photo" alt="Ivan Xiao"><div class="author-info"><div class="author-name">
        <span class="p-name">Ivan Xiao</span>
      </div><ul class="author-links"><li class="author-link">
            <a class="u-url" rel="me" href="https://about.me/iveney"><i class="fas fa-external-link-square-alt fa-lg" title="About"></i></a>
          </li><li class="author-link">
            <a class="u-url" rel="me" href="https://twitter.com/ivanzxiao"><i class="fab fa-twitter-square fa-lg" title="Twitter"></i></a>
          </li><li class="author-link">
            <a class="u-url" rel="me" href="https://github.com/iveney"><i class="fab fa-github-square fa-lg" title="GitHub"></i></a>
          </li></ul>

<span class="read-time">4 min read</span>

    <time class="page-date dt-published" datetime="2014-05-19T20:12:36+00:00"><a class="u-url" href="">May 19, 2014</a>
</time>

  </div>
</div>

        
  <h3 class="page-taxonomies-title">Categories</h3>
  <ul class="page-taxonomies"><li class="page-taxonomy"><a class="p-category" href="/categories/#machine-learning" title="Pages filed under machine learning">machine learning</a></li><li class="page-taxonomy"><a class="p-category" href="/categories/#signal-processing" title="Pages filed under signal processing">signal processing</a></li>
  </ul>


        

      </div>

      <div class="page-content">
        <div class="e-content">
          <hr />
<p>nocite:
  ‘@candes2005l1, @hesthavensparse, @pant2013new, @candes2006robust’
—</p>

<hr />
<p><img src="https://res.cloudinary.com/maomao/image/upload/v1491291930/blog/l1/phantom_orig.png" alt="phantom_orig" />\      <img src="https://res.cloudinary.com/maomao/image/upload/v1491291930/blog/l1/phantom_backproj.png" alt="phantom_backproj" />\              <img src="https://res.cloudinary.com/maomao/image/upload/v1491291930/blog/l1/phantom_tv.png" alt="phantom_tv" /><br />
    Original           Minimum Energy Reconstruction     Sparse Reconstruction
——————–  ——————————-  ————————-</p>

<h2 id="introduction">Introduction</h2>

<p>This is a follow up of the L1-minimization series. The previous two posts are:</p>

<ol>
  <li><a href="/2014/05/15/a-comparison-of-least-square-l2-regularization-and-l1-regularization">A Comparison of Least Square, L2-regularization and L1-regularization</a></li>
  <li><a href="/2014/05/19/sparse-signal-reconstruction-via-l1-minimization">Sparse Signal Reconstruction via L1-minimization</a>
<!-- more --></li>
</ol>

<p>We have explored using L1-minimization technique to
<a href="/2014/05/19/sparse-signal-reconstruction-via-l1-minimization">recover a sparse signal</a>.
The example shows a 1D example. This post demonsrates  on a 2D example, where
the image is viewed as a signal. This makes sense as we can perform 2D Fourier
Transform in the image, where the basis are a combination of <em>horizontal</em> and
<em>vertical</em> waves. For a complete introduction to FFT on images, refer to
<a href="http://www.cs.unm.edu/~brayer/vision/fourier.html">this tutorial</a>. Notice that similar to 1D signal, we do not measure
the image directly in time domain, but we do it in the frequency domain.
Concretely, say \(x\) is the 2D image collapsed to 1D, and \(A \in \reals^{k\times n}\)
is the measurement matrix, \(b\) is the observation, we then have \(Ax=b\).
Usually we will require \(k = n\) to obtain an exact solution for \(x\) given \(A\)
and \(b\). Now, if we use FFT and obtain the frequency coefficients as \(\hat{x}\),
we can also perform similar measurements \(\hat{A} \hat{x} = \hat{b}\),
and the requirement \(k = n\) is the same. In other words, the required samples
(the information) is <em>the same</em>. By using the inverse fourier transform,
we can convert \(\hat{x}\) back to \(x\). The only difference is that the measurement
\(\hat{A}\) is taken in frequency (Fourier) domain. As we can see later, we can
utilize sparse information to reduce \(k\).</p>

<h2 id="image-gradients-and-total-variation">Image Gradients and Total Variation</h2>

<p>We first introduct the concept of image gradients. For any 2D real image <code class="language-plaintext highlighter-rouge">I</code>, if
we think about each row as a signal, we can then view the ‘difference’ between
adjacent pixels as (horizontal) gradient <code class="language-plaintext highlighter-rouge">Gx(I)</code>, this makes sense since a
sharpe change denotes an edge. Similary, we can define the vertical gradient
<code class="language-plaintext highlighter-rouge">Gy(I)</code> for columns. Thus, we have</p>

\[Gx(I) = \begin{cases}
I_{i+1, j} - I_{ij} &amp; i &lt; n \\\\ 0 &amp; i = n
\end{cases}
\qquad
Gy(I) = \begin{cases}
I_{i, j+1} - I_{ij} &amp; j &lt; n \\\\ 0 &amp; j = n
\end{cases}\]

<p>where the image size is \(n\times n\).</p>

<p>Collectively, the image gradient <code class="language-plaintext highlighter-rouge">G(I)</code> is defined as the
magnitude (2-norm) of both components:</p>

\[G(I)_{ij} = \sqrt{(Gx(I)_{ij})^2 + (Gy(I)_{ij})^2}\]

<p>The following shows <code class="language-plaintext highlighter-rouge">Gx</code>, <code class="language-plaintext highlighter-rouge">Gy</code> and <code class="language-plaintext highlighter-rouge">G</code> of the phantom image:</p>

<hr />
<p><img src="https://res.cloudinary.com/maomao/image/upload/v1491291930/blog/l1/phantom_gx.png" alt="phantom_gx" />\     <img src="https://res.cloudinary.com/maomao/image/upload/v1491291930/blog/l1/phantom_gy.png" alt="phantom_gy" />\     <img src="https://res.cloudinary.com/maomao/image/upload/v1491291930/blog/l1/phantom_gI.png" alt="phantom_gI" /><br />
    <code class="language-plaintext highlighter-rouge">Gx(I)</code>             <code class="language-plaintext highlighter-rouge">Gy(I)</code>             <code class="language-plaintext highlighter-rouge">G(I)</code>
—————–  —————–  —————–</p>

<p>The <em>total variation</em> <code class="language-plaintext highlighter-rouge">TV(I)</code> of an image is just the sum of
this discrete gradient at every point.</p>

\[TV(I)= \norm{G(I)}_1 = \sum_{i,j} G(I)_{ij}\]

<p>We notice that \(TV(I)\) is just the <em>L1-norm</em> of \(G(I)\),
which leads us to the following: if we have an image that is sparse in
its image gradients, we can exploit that and use our L1-minimization trick.</p>

<h2 id="sparse-gradient-image-reconstruction">Sparse Gradient Image Reconstruction</h2>

<p>The ratio of non-zero elements in <code class="language-plaintext highlighter-rouge">Gx</code>, <code class="language-plaintext highlighter-rouge">Gy</code> and <code class="language-plaintext highlighter-rouge">G</code> of the phantom image
is <code class="language-plaintext highlighter-rouge">0.0711</code>, <code class="language-plaintext highlighter-rouge">0.0634</code> and <code class="language-plaintext highlighter-rouge">0.0769</code>, respectively. These ratios are really
small - and we consider the gradient as <em>sparse</em>.</p>

<p>Let \(F: \reals^{n\times n} \to \complex^{n\times n}\) be the FFT operator,
and \(F I\) be the Fourier transform taken on image I.
Define a set \(\Omega\) as the \(k\) two-dimensional frequencies chosen
according to some sampling pattern from the \(n \times n\).
We further define \(F_\Omega I: \reals^{n \times n} \to \complex^k\) as the
\(k\) observation taken from the fourier transform of image I.
We can then solve the following optimization problem to recover \(I\):</p>

\[\min_I \norm{F_\Omega I - b}^2_2\]

<p>where \(F_\Omega\) can be view as the measurement matrix, \(b\) is the observation,
and we want to find \(I\) such that the <em>reconstruction cost</em> (energy) is
minimized.</p>

<p>However, the above does not quite work. As we can see in the following images,
the <em>L2-minimization</em> does a poor job, either for a random measurement or
a radial measurement [@candes2006robust] in Fourier domain.</p>

<hr />
<p><img src="https://res.cloudinary.com/maomao/image/upload/v1491291930/blog/l1/measurement_random.png" alt="M rand" />            <img src="https://res.cloudinary.com/maomao/image/upload/v1491291930/blog/l1/phantom_rand_bp.png" alt="phantom rand bp" />     <img src="https://res.cloudinary.com/maomao/image/upload/v1491291930/blog/l1/phantom_rand_tv.png" alt="phantom rand tv" />
 Random measurement     L2-minimization        L1-minimization
——————–  ———————  ——————–</p>

<hr />
<p><img src="https://res.cloudinary.com/maomao/image/upload/v1491291930/blog/l1/measurement_radial.png" alt="M radial" />          <img src="https://res.cloudinary.com/maomao/image/upload/v1491291930/blog/l1/phantom_backproj.png" alt="phantom_backproj" />     <img src="https://res.cloudinary.com/maomao/image/upload/v1491291930/blog/l1/phantom_tv.png" alt="phantom_tv" />
 Radial measurement     L2-minimization       L1-minimization
——————–  ———————  ——————–</p>

<p>To utilize the sparse information, we add a L1-regularization term
to the above objective function, which yields the following:</p>

\[(TV_1) \quad \min_I \norm{F_\Omega I - b}^2_2 + \lambda TV(I)\]

<p>Without surprise, optimizing the above gives us a <em>perfect</em> reconstruction
of the original image.
It is shown that if there exists a piecewise constant I with sufficiently
few edges (i.e., \(G(I)_{ij}\) is nonzero for only a small number of indices i, j),
then \((TV_1)\) will recover I exactly.</p>

<p>A heavily commented code example is available in my <a href="https://github.com/iveney/l1min/blob/master/image_recovery_l1.m">github repository</a>.
Leave a comment if you have any question.</p>

<h2 id="probing-further">Probing Further</h2>

<p>Now, take a look at another example <code class="language-plaintext highlighter-rouge">cameraman</code>, which has the following
gradients (intensity rescaled using matlab’s <code class="language-plaintext highlighter-rouge">imagesc</code>.</p>

<hr />
<p><img src="https://res.cloudinary.com/maomao/image/upload/v1491291930/blog/l1/cameraman.png" alt="cameraman" />       <img src="https://res.cloudinary.com/maomao/image/upload/v1491291930/blog/l1/cameraman_grad.png" alt="cameraman_grad" />
    Cameraman             Gradient
——————  ——————–</p>

<p>The following shows the reconstructions (left two are using random measurements,
right two are using radial measurements).</p>

<hr />
<p><img src="https://res.cloudinary.com/maomao/image/upload/v1491291930/blog/l1/cameraman_rand_bp.png" alt="cameraman_rand_bp" />    <img src="https://res.cloudinary.com/maomao/image/upload/v1491291930/blog/l1/cameraman_rand_tv.png" alt="cameraman_rand_tv" />    <img src="https://res.cloudinary.com/maomao/image/upload/v1491291930/blog/l1/cameraman_bp.png" alt="cameraman_bp" />    <img src="https://res.cloudinary.com/maomao/image/upload/v1491291930/blog/l1/cameraman_tv.png" alt="cameraman_tv" />
      Rand (L2)             Rand (L1)              Radial (L2)        Radial (L1)
———————-  ———————-  —————–  —————–</p>

<p>As we can see, the results are not as good. In fact, the non-zero ratio of its
gradient is 0.9928, which is not sparse at all. However, if we plot the histogram
of gradients, we will find that most of the gradient magnitudes are small:</p>

<p><img src="https://res.cloudinary.com/maomao/image/upload/v1491291930/blog/l1/camera_mag_hist.png" alt="Gradient Histogram" /></p>

<p>In particular, most of them are smaller than 200, which means the number of
‘changes’ that are larger than 200 is small. In fact, the ratio of
gradient &gt; 200 is only <em>0.0964</em>! Thus, there are two possible ways to
discard these information and get a ‘compressed’ image that is
sparse in gradients:</p>

<ol>
  <li>Use mean-shift algorithm to segment the regions such that they have the
same color intensities. K-means or quantization should achieve a similar
result, though might not as good as mean-shift.</li>
  <li>Use image filtering to smooth the image, which can effectively average colors
and discard high frequency information.</li>
</ol>

<p><em>I’ll leave these conjectures for furture implementation. For those
intereted, please try them yourself and let me know your results.
If you have any thoughts, do not hesitate to leave a comment.</em></p>

<h2 id="references">References</h2>

<p>For interested readers, the following references will be helpful.</p>


        </div>

        

        
          

        

        <nav class="page-pagination" role="navigation">
  
    <a class="page-previous" href="/2014/05/19/sparse-signal-reconstruction-via-l1-minimization">
      <h4 class="page-pagination-label">Previous</h4>
      <span class="page-pagination-title">
        <i class="fas fa-arrow-left"></i> Sparse Signal Reconstruction via L1-minimization

      </span>
    </a>
  

  
    <a class="page-next" href="/2014/05/23/my-octopress-blogging-flow">
      <h4 class="page-pagination-label">Next</h4>
      <span class="page-pagination-title">
        My Octopress Blogging Flow
 <i class="fas fa-arrow-right"></i>
      </span>
    </a>
  
</nav>

      </div>
    </div>
  </article>
</main>


    <footer id="footer" class="site-footer">
  <!-- start custom footer snippets -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
  TeX: {
    extensions: ["mediawiki-texvc.js"],
    Macros: {
      complex: ['\\mathbb{C}'],
      norm: ['\\left\\lVert#1\\right\\rVert', 1],
      given: ['\\mathbin{\\vert}'],
      data: ['\\mathcal{D}'],
      argmax: ['\\mathop{\\arg\\,\\max}\\limits'],
    }
  }
  });
</script>
<!-- end custom footer snippets -->
<div class="social-icons"><a class="social-icon" href="https://about.me/iveney"><i class="fas fa-external-link-square-alt fa-2x" title="About"></i></a><a class="social-icon" href="https://twitter.com/ivanzxiao"><i class="fab fa-twitter-square fa-2x" title="Twitter"></i></a><a class="social-icon" href="https://github.com/iveney"><i class="fab fa-github-square fa-2x" title="GitHub"></i></a><a class="social-icon" href="https://www.linkedin.com/in/zgxiao/"><i class="fab fa-linkedin fa-2x" title="LinkedIn"></i></a><a class="social-icon" href="/atom.xml"><i class="fas fa-rss-square fa-2x" title="Feed"></i></a></div><div class="copyright">
    
      <p>&copy; 2021 Ivan Xiao. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://github.com/mmistakes/so-simple-theme" rel="nofollow">So Simple</a>.</p>
    
  </div>
</footer>

    <script src="https://code.jquery.com/jquery-3.3.1.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script>
  <script src="/assets/js/main.min.js"></script>
  <script src="https://use.fontawesome.com/releases/v5.0.12/js/all.js"></script>


<!-- MathJax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  </body>

</html>
